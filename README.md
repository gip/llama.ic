# `yllama.oc`

An on-chain implementation of inference for Llama 3 8b. This is work-in-progress as deployment to the Internet Computer (ICP) is happening. This repo will be updated shortly with more documentation and the code used to push to the mainnet.

This repo maps the implementation of the Llama 3 inference engine implemented [here](https://github.com/gip/yllama.rs) to ICP.

## Building

Coming soon.

## Contact

gip.github@gmail.com

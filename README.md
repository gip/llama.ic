# yllama.oc

An on-chain implementation of inference for Llama 3 8b. This is currently work-in-progress as deployment to the Internet Computer (ICP) is happening at the moment. This repo will be updated shortly with more documentation and the actual code used to push to the mainnet.

This repo maps the implementation of the Llama 3 inference engine implemented [here](https://github.com/gip/yllama.rs) to ICP.

## Building

Coming soon.

## Contact

gip.github@gmail.com
